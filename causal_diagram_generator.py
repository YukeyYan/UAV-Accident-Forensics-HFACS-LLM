"""
Causal Diagram Automatic Generator
Automatically generate causal relationship diagrams based on incident narratives for accident investigation and root cause analysis
"""

import requests
import json
import logging
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass
from datetime import datetime
import os
import re
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import networkx as nx
import numpy as np
from translations import get_text

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class CausalNode:
    """Causal Relationship Node"""
    id: str
    name: str
    type: str  # 'root_cause', 'contributing_factor', 'immediate_cause', 'consequence'
    description: str
    likelihood: float  # 0.0-1.0
    impact: float  # 0.0-1.0
    evidence_strength: float  # 0.0-1.0
    category: str  # 'human', 'technical', 'environmental', 'organizational'

@dataclass
class CausalRelationship:
    """Causal Relationship Connection"""
    from_node: str
    to_node: str
    relationship_type: str  # 'direct_cause', 'contributing_cause', 'enabling_condition'
    strength: float  # 0.0-1.0
    confidence: float  # 0.0-1.0
    description: str

@dataclass
class CausalDiagram:
    """Causal Relationship Diagram"""
    nodes: List[CausalNode]
    relationships: List[CausalRelationship]
    central_event: str
    timeline: List[Dict[str, Any]]
    risk_paths: List[List[str]]  # Risk propagation paths
    control_points: List[Dict[str, Any]]  # Control points
    metadata: Dict[str, Any]

class CausalDiagramGenerator:
    """Causal Diagram Generator"""
    
    def __init__(self, api_key: Optional[str] = None, model: str = "gpt-4o-mini"):
        """
        Initialize Causal Diagram Generator
        
        Args:
            api_key: OpenAI API key
            model: Model to use (gpt-4o or gpt-4o-mini)
        """
        self.api_key = api_key or os.getenv('OPENAI_API_KEY') or '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'
        self.model = model
        self.use_mock = not bool(self.api_key)
        
        # Define node category colors
        self.node_colors = {
            'root_cause': '#e74c3c',        # Red - Root cause
            'contributing_factor': '#f39c12', # Orange - Contributing factor  
            'immediate_cause': '#e67e22',    # Dark orange - Immediate cause
            'consequence': '#9b59b6',        # Purple - Consequence
            'control_point': '#27ae60'       # Green - Control point
        }
        
        # å®šä¹‰ç±»åˆ«é¢œè‰²
        self.category_colors = {
            'human': '#3498db',          # è“è‰² - äººä¸ºå› ç´ 
            'technical': '#e74c3c',      # çº¢è‰² - æŠ€æœ¯å› ç´ 
            'environmental': '#27ae60',  # ç»¿è‰² - ç¯å¢ƒå› ç´ 
            'organizational': '#f39c12', # æ©™è‰² - ç»„ç»‡å› ç´ 
            'procedural': '#9b59b6'      # ç´«è‰² - ç¨‹åºå› ç´ 
        }
        
        self.system_prompt = """You are a world-class incident investigation expert and causal analysis specialist with expertise in:

ğŸ¯ CORE COMPETENCIES:
â€¢ Root Cause Analysis (RCA) methodologies
â€¢ Causal mapping and systems thinking
â€¢ Aviation accident investigation (NTSB, ICAO standards)
â€¢ Human factors analysis (HFACS, SHELL model)
â€¢ Swiss Cheese model and barrier analysis
â€¢ Bow-tie risk analysis
â€¢ Failure Mode and Effects Analysis (FMEA)
â€¢ Event and fault tree analysis

ğŸ“Š CAUSAL ANALYSIS FRAMEWORK:
Your mission is to analyze incident narratives and construct comprehensive causal diagrams that reveal the complex web of factors leading to the event.

ğŸ” NODE CLASSIFICATION:
1. **Root Causes** - Fundamental system deficiencies that, if corrected, would prevent recurrence
2. **Contributing Factors** - Conditions that increased likelihood but didn't directly cause the event
3. **Immediate Causes** - Direct precipitating factors that triggered the event
4. **Consequences** - Direct and indirect outcomes of the event

ğŸ“‹ FACTOR CATEGORIES:
â€¢ **Human Factors**: Decision errors, skill deficiencies, violations, communication failures
â€¢ **Technical Factors**: Equipment failures, design deficiencies, maintenance issues
â€¢ **Environmental Factors**: Weather, lighting, terrain, external hazards  
â€¢ **Organizational Factors**: Policies, procedures, culture, resource allocation
â€¢ **Procedural Factors**: Inadequate procedures, procedure violations, gaps

âš–ï¸ ASSESSMENT DIMENSIONS:
â€¢ **Likelihood** (0.0-1.0): Probability this factor contributed to the event
â€¢ **Impact** (0.0-1.0): Magnitude of influence on event occurrence/severity
â€¢ **Evidence Strength** (0.0-1.0): Quality and reliability of supporting evidence
â€¢ **Relationship Strength** (0.0-1.0): Certainty of causal connection

ğŸ¯ ANALYSIS PRINCIPLES:
â€¢ Apply systems thinking to identify complex interactions
â€¢ Consider multiple causal pathways and feedback loops
â€¢ Distinguish between necessary and sufficient causes
â€¢ Identify both active failures and latent conditions
â€¢ Focus on systemic factors rather than individual blame
â€¢ Consider prevention and mitigation opportunities

ğŸ”— RELATIONSHIP TYPES:
â€¢ **Direct Cause**: Factor X directly produced outcome Y
â€¢ **Contributing Cause**: Factor X increased likelihood of outcome Y
â€¢ **Enabling Condition**: Factor X made outcome Y possible

Your analysis should provide actionable insights for prevention and risk mitigation while maintaining scientific rigor and objectivity."""
    
    def generate_causal_diagram(self, narrative: str, incident_data: Dict = None) -> CausalDiagram:
        """
        åŸºäºå™è¿°ç”Ÿæˆå› æœå›¾
        
        Args:
            narrative: äº‹æ•…å™è¿°
            incident_data: é¢å¤–çš„äº‹æ•…æ•°æ®
            
        Returns:
            CausalDiagram: ç”Ÿæˆçš„å› æœå›¾
        """
        try:
            if self.use_mock:
                return self._generate_mock_diagram(narrative, incident_data)
            else:
                return self._generate_ai_diagram(narrative, incident_data)
        except Exception as e:
            logger.error(f"å› æœå›¾ç”Ÿæˆå¤±è´¥: {e}")
            return self._generate_fallback_diagram(narrative, incident_data)
    
    def _generate_ai_diagram(self, narrative: str, incident_data: Dict = None) -> CausalDiagram:
        """ä½¿ç”¨AIç”Ÿæˆå› æœå›¾"""
        
        # æ„å»ºåˆ†ææç¤º
        prompt = self._build_causal_analysis_prompt(narrative, incident_data)
        
        try:
            url = "https://api.openai.com/v1/chat/completions"
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }

            data = {
                "model": self.model,
                "messages": [
                    {"role": "system", "content": self.system_prompt},
                    {"role": "user", "content": prompt}
                ],
                "functions": [self._create_causal_function_schema()],
                "function_call": {"name": "analyze_causal_relationships"},
                "temperature": 0.1,
                "max_tokens": 3000
            }

            response = requests.post(url, headers=headers, json=data, timeout=60)

            if response.status_code == 200:
                result = response.json()
                message = result['choices'][0]['message']

                if 'function_call' in message:
                    function_result = json.loads(message['function_call']['arguments'])
                    return self._parse_causal_result(function_result, narrative)
                else:
                    return self._generate_fallback_diagram(narrative, incident_data)
            else:
                logger.error(f"AIåˆ†æå¤±è´¥: {response.status_code}")
                return self._generate_fallback_diagram(narrative, incident_data)

        except Exception as e:
            logger.error(f"AIå› æœåˆ†æå¤±è´¥: {e}")
            return self._generate_fallback_diagram(narrative, incident_data)
    
    def _build_causal_analysis_prompt(self, narrative: str, incident_data: Dict = None) -> str:
        """æ„å»ºå› æœåˆ†ææç¤º"""
        
        additional_info = ""
        if incident_data:
            additional_info = f"\n**Additional Context:**\n"
            for key, value in incident_data.items():
                if value:
                    additional_info += f"- {key}: {value}\n"
        
        prompt = f"""Conduct a comprehensive causal analysis of the following UAV/UAS incident narrative:

**INCIDENT NARRATIVE:**
{narrative}
{additional_info}

**ANALYSIS REQUIREMENTS:**

ğŸ¯ **PRIMARY OBJECTIVES:**
1. Identify all causal factors contributing to the incident
2. Establish causal relationships and dependencies
3. Classify factors by type and category
4. Assess likelihood, impact, and evidence strength
5. Map risk propagation pathways
6. Identify control points for prevention

ğŸ“Š **REQUIRED ANALYSIS:**

**1. ROOT CAUSE IDENTIFICATION**
- What fundamental system deficiencies enabled this incident?
- What organizational or design factors created the conditions for failure?
- Which factors, if addressed, would prevent similar occurrences?

**2. CONTRIBUTING FACTOR ANALYSIS**
- What conditions increased the likelihood of the incident?
- How did multiple factors interact to create the incident scenario?
- What latent conditions existed in the system?

**3. IMMEDIATE CAUSE MAPPING**
- What direct triggers precipitated the event?
- What was the sequence of immediate failures or errors?
- How did the incident unfold chronologically?

**4. CONSEQUENCE ASSESSMENT**
- What were the direct outcomes of the incident?
- What secondary effects or cascading failures occurred?
- How did consequences propagate through the system?

**5. CONTROL POINT IDENTIFICATION**
- Where could the incident progression have been interrupted?
- What barriers failed or were absent?
- What intervention points exist for prevention?

ğŸ” **FACTOR CATEGORIZATION:**
Classify each factor into:
- **Human**: Pilot error, training deficiency, decision-making, communication
- **Technical**: Equipment failure, design flaw, maintenance, software
- **Environmental**: Weather, terrain, obstacles, external conditions  
- **Organizational**: Policy, procedure, culture, resources, oversight
- **Procedural**: Process gaps, non-compliance, inadequate procedures

âš–ï¸ **QUANTITATIVE ASSESSMENT:**
For each factor, provide:
- **Likelihood** (0.0-1.0): How probable was this factor's contribution?
- **Impact** (0.0-1.0): How significantly did this factor influence the outcome?
- **Evidence Strength** (0.0-1.0): How well-supported is this factor by evidence?

ğŸ”— **RELATIONSHIP MAPPING:**
Define causal relationships:
- **Direct Cause**: X directly caused Y
- **Contributing Cause**: X increased likelihood of Y  
- **Enabling Condition**: X made Y possible

**TIMELINE INTEGRATION:**
Establish temporal sequence showing how factors developed and interacted over time.

**PREVENTION FOCUS:**
Identify specific, actionable intervention points that could break the causal chain and prevent recurrence."""
        
        return prompt
    
    def _create_causal_function_schema(self):
        """åˆ›å»ºå› æœåˆ†æçš„Function Schema"""
        return {
            "name": "analyze_causal_relationships",
            "description": "Analyze incident narrative and generate comprehensive causal diagram data",
            "parameters": {
                "type": "object",
                "properties": {
                    "central_event": {
                        "type": "string",
                        "description": "Primary incident or failure event"
                    },
                    "causal_nodes": {
                        "type": "array",
                        "description": "All causal factors identified in the analysis",
                        "items": {
                            "type": "object",
                            "properties": {
                                "id": {"type": "string", "description": "Unique identifier"},
                                "name": {"type": "string", "description": "Factor name"},
                                "type": {
                                    "type": "string", 
                                    "enum": ["root_cause", "contributing_factor", "immediate_cause", "consequence"],
                                    "description": "Factor classification"
                                },
                                "description": {"type": "string", "description": "Detailed description"},
                                "likelihood": {
                                    "type": "number", 
                                    "minimum": 0.0, 
                                    "maximum": 1.0,
                                    "description": "Probability of contribution (0.0-1.0)"
                                },
                                "impact": {
                                    "type": "number", 
                                    "minimum": 0.0, 
                                    "maximum": 1.0,
                                    "description": "Magnitude of influence (0.0-1.0)"
                                },
                                "evidence_strength": {
                                    "type": "number", 
                                    "minimum": 0.0, 
                                    "maximum": 1.0,
                                    "description": "Quality of supporting evidence (0.0-1.0)"
                                },
                                "category": {
                                    "type": "string",
                                    "enum": ["human", "technical", "environmental", "organizational", "procedural"],
                                    "description": "Factor category"
                                }
                            },
                            "required": ["id", "name", "type", "description", "likelihood", "impact", "evidence_strength", "category"]
                        }
                    },
                    "causal_relationships": {
                        "type": "array",
                        "description": "Relationships between causal factors",
                        "items": {
                            "type": "object",
                            "properties": {
                                "from_node": {"type": "string", "description": "Source factor ID"},
                                "to_node": {"type": "string", "description": "Target factor ID"},
                                "relationship_type": {
                                    "type": "string",
                                    "enum": ["direct_cause", "contributing_cause", "enabling_condition"],
                                    "description": "Type of causal relationship"
                                },
                                "strength": {
                                    "type": "number",
                                    "minimum": 0.0,
                                    "maximum": 1.0,
                                    "description": "Strength of causal connection"
                                },
                                "confidence": {
                                    "type": "number",
                                    "minimum": 0.0,
                                    "maximum": 1.0,
                                    "description": "Confidence in relationship"
                                },
                                "description": {"type": "string", "description": "Relationship description"}
                            },
                            "required": ["from_node", "to_node", "relationship_type", "strength", "confidence", "description"]
                        }
                    },
                    "timeline": {
                        "type": "array",
                        "description": "Chronological sequence of events",
                        "items": {
                            "type": "object",
                            "properties": {
                                "time": {"type": "string", "description": "Time reference"},
                                "event": {"type": "string", "description": "Event description"},
                                "factors": {"type": "array", "items": {"type": "string"}, "description": "Associated factor IDs"},
                                "criticality": {"type": "string", "enum": ["low", "medium", "high", "critical"]}
                            }
                        }
                    },
                    "risk_paths": {
                        "type": "array",
                        "description": "Risk propagation pathways",
                        "items": {
                            "type": "array",
                            "items": {"type": "string"},
                            "description": "Sequence of factor IDs showing risk propagation"
                        }
                    },
                    "control_points": {
                        "type": "array",
                        "description": "Potential intervention points",
                        "items": {
                            "type": "object",
                            "properties": {
                                "name": {"type": "string", "description": "Control point name"},
                                "description": {"type": "string", "description": "Intervention description"},
                                "effectiveness": {"type": "number", "minimum": 0.0, "maximum": 1.0},
                                "associated_factors": {"type": "array", "items": {"type": "string"}}
                            }
                        }
                    }
                },
                "required": ["central_event", "causal_nodes", "causal_relationships", "timeline", "risk_paths", "control_points"]
            }
        }
    
    def _parse_causal_result(self, result: Dict, narrative: str) -> CausalDiagram:
        """è§£æAIåˆ†æç»“æœ"""
        
        # è§£æèŠ‚ç‚¹
        nodes = []
        for node_data in result.get("causal_nodes", []):
            node = CausalNode(
                id=node_data["id"],
                name=node_data["name"],
                type=node_data["type"],
                description=node_data["description"],
                likelihood=node_data["likelihood"],
                impact=node_data["impact"],
                evidence_strength=node_data["evidence_strength"],
                category=node_data["category"]
            )
            nodes.append(node)
        
        # è§£æå…³ç³»
        relationships = []
        for rel_data in result.get("causal_relationships", []):
            relationship = CausalRelationship(
                from_node=rel_data["from_node"],
                to_node=rel_data["to_node"],
                relationship_type=rel_data["relationship_type"],
                strength=rel_data["strength"],
                confidence=rel_data["confidence"],
                description=rel_data["description"]
            )
            relationships.append(relationship)
        
        return CausalDiagram(
            nodes=nodes,
            relationships=relationships,
            central_event=result.get("central_event", "Incident Event"),
            timeline=result.get("timeline", []),
            risk_paths=result.get("risk_paths", []),
            control_points=result.get("control_points", []),
            metadata={
                "generation_time": datetime.now().isoformat(),
                "narrative_length": len(narrative),
                "analysis_method": "AI-based",
                "confidence": "high"
            }
        )
    
    def _generate_mock_diagram(self, narrative: str, incident_data: Dict = None) -> CausalDiagram:
        """ç”Ÿæˆæ¨¡æ‹Ÿå› æœå›¾"""
        
        narrative_lower = narrative.lower()
        
        # åŸºäºå™è¿°å†…å®¹ç”ŸæˆèŠ‚ç‚¹
        nodes = []
        relationships = []
        
        # Root causes
        if 'communication' in narrative_lower or 'link' in narrative_lower:
            nodes.append(CausalNode(
                id="rc_comm_system",
                name="Communication System Design Deficiency",
                type="root_cause",
                description="Communication system lacks sufficient redundancy and fault recovery mechanisms",
                likelihood=0.8,
                impact=0.9,
                evidence_strength=0.7,
                category="technical"
            ))
            
            nodes.append(CausalNode(
                id="ic_comm_loss",
                name="Communication Link Interruption", 
                type="immediate_cause",
                description="Communication connection between UAV and ground station suddenly interrupted",
                likelihood=0.9,
                impact=0.8,
                evidence_strength=0.9,
                category="technical"
            ))
            
            relationships.append(CausalRelationship(
                from_node="rc_comm_system",
                to_node="ic_comm_loss",
                relationship_type="direct_cause",
                strength=0.8,
                confidence=0.7,
                description="Design deficiency leads to communication interruption"
            ))
        
        # Human factors
        if 'pilot' in narrative_lower or 'operator' in narrative_lower:
            nodes.append(CausalNode(
                id="cf_pilot_training",
                name="Insufficient Pilot Emergency Training",
                type="contributing_factor", 
                description="Lack of sufficient emergency procedure training for communication failures",
                likelihood=0.6,
                impact=0.7,
                evidence_strength=0.5,
                category="human"
            ))
        
        # ç¯å¢ƒå› ç´ 
        if 'weather' in narrative_lower or 'wind' in narrative_lower:
            nodes.append(CausalNode(
                id="cf_weather",
                name="Adverse Weather Conditions",
                type="contributing_factor",
                description="Adverse weather conditions affected flight operations and communication quality",
                likelihood=0.5,
                impact=0.6,
                evidence_strength=0.8,
                category="environmental"
            ))
        
        # åæœ
        nodes.append(CausalNode(
            id="cons_control_loss",
            name="Loss of Aircraft Control",
            type="consequence",
            description="Operator unable to continue controlling UAV flight path and operations",
            likelihood=0.9,
            impact=1.0,
            evidence_strength=0.9,
            category="technical"
        ))
        
        # å¦‚æœèŠ‚ç‚¹å¤ªå°‘ï¼Œæ·»åŠ é»˜è®¤èŠ‚ç‚¹
        if len(nodes) < 3:
            nodes.extend([
                CausalNode(
                    id="rc_system_design",
                    name="Inadequate System Design",
                    type="root_cause",
                    description="UAV system did not adequately consider failure modes during design phase",
                    likelihood=0.7,
                    impact=0.8,
                    evidence_strength=0.6,
                    category="organizational"
                ),
                CausalNode(
                    id="cf_maintenance",
                    name="Maintenance Procedure Deficiency",
                    type="contributing_factor",
                    description="Equipment maintenance inspection procedures are inadequate",
                    likelihood=0.5,
                    impact=0.6,
                    evidence_strength=0.4,
                    category="procedural"
                )
            ])
        
        # ç”ŸæˆåŸºæœ¬å…³ç³»
        if len(relationships) == 0:
            for i in range(len(nodes) - 1):
                relationships.append(CausalRelationship(
                    from_node=nodes[i].id,
                    to_node=nodes[i + 1].id,
                    relationship_type="contributing_cause" if i % 2 == 0 else "direct_cause",
                    strength=0.7 - i * 0.1,
                    confidence=0.6 - i * 0.05,
                    description=f"{nodes[i].name} leads to {nodes[i + 1].name}"
                ))
        
        # æ—¶é—´çº¿
        timeline = [
            {"time": "T-30 min", "event": "Normal flight preparation", "factors": [], "criticality": "low"},
            {"time": "T-10 min", "event": "Flight mission commenced", "factors": [], "criticality": "low"}, 
            {"time": "T-2 min", "event": "Abnormal signs appeared", "factors": [nodes[0].id if nodes else ""], "criticality": "medium"},
            {"time": "T=0", "event": "Incident occurred", "factors": [node.id for node in nodes[-2:] if nodes], "criticality": "critical"},
            {"time": "T+5 min", "event": "Emergency response initiated", "factors": [], "criticality": "high"}
        ]
        
        # é£é™©è·¯å¾„
        risk_paths = []
        if len(nodes) >= 3:
            risk_paths.append([nodes[0].id, nodes[1].id, nodes[-1].id])
        
        # æ§åˆ¶ç‚¹
        control_points = [
            {
                "name": "é¢„é˜²æ€§ç»´æŠ¤æ£€æŸ¥",
                "description": "åŠ å¼ºè®¾å¤‡é¢„é˜²æ€§ç»´æŠ¤å’Œæ•…éšœé¢„æµ‹",
                "effectiveness": 0.8,
                "associated_factors": [nodes[0].id if nodes else ""]
            },
            {
                "name": "åº”æ€¥ç¨‹åºåŸ¹è®­",
                "description": "å¼ºåŒ–æ“ä½œå‘˜åº”æ€¥æƒ…å†µå¤„ç½®åŸ¹è®­",
                "effectiveness": 0.7,
                "associated_factors": [node.id for node in nodes if node.category == "human"]
            }
        ]
        
        return CausalDiagram(
            nodes=nodes,
            relationships=relationships,
            central_event="UAVé€šä¿¡æ•…éšœäº‹æ•…",
            timeline=timeline,
            risk_paths=risk_paths,
            control_points=control_points,
            metadata={
                "generation_time": datetime.now().isoformat(),
                "narrative_length": len(narrative),
                "analysis_method": "Rule-based mock",
                "confidence": "medium"
            }
        )
    
    def _generate_fallback_diagram(self, narrative: str, incident_data: Dict = None) -> CausalDiagram:
        """ç”Ÿæˆå¤‡ç”¨å› æœå›¾"""
        
        # ç®€å•çš„å¤‡ç”¨å›¾
        nodes = [
            CausalNode(
                id="unknown_root",
                name="Undetermined Root Cause",
                type="root_cause", 
                description="Further investigation required to determine root cause",
                likelihood=0.5,
                impact=0.5,
                evidence_strength=0.3,
                category="technical"
            ),
            CausalNode(
                id="incident_event",
                name="Incident Event",
                type="immediate_cause",
                description="Incident event based on narrative description",
                likelihood=1.0,
                impact=1.0,
                evidence_strength=1.0,
                category="technical"
            )
        ]
        
        relationships = [
            CausalRelationship(
                from_node="unknown_root",
                to_node="incident_event",
                relationship_type="direct_cause",
                strength=0.5,
                confidence=0.3,
                description="Causal relationship requiring further analysis"
            )
        ]
        
        return CausalDiagram(
            nodes=nodes,
            relationships=relationships,
            central_event="éœ€è¦è¿›ä¸€æ­¥åˆ†æçš„äº‹æ•…",
            timeline=[],
            risk_paths=[],
            control_points=[],
            metadata={
                "generation_time": datetime.now().isoformat(),
                "narrative_length": len(narrative),
                "analysis_method": "Fallback",
                "confidence": "low"
            }
        )
    
    def create_causal_visualization(self, diagram: CausalDiagram, lang: str = 'zh') -> go.Figure:
        """åˆ›å»ºå› æœå›¾å¯è§†åŒ–"""
        
        if not diagram.nodes:
            # ç©ºå›¾çš„æƒ…å†µ
            fig = go.Figure()
            fig.add_annotation(
                x=0.5, y=0.5,
                text="ğŸ”§ å› æœå›¾ç”Ÿæˆä¸­...<br><br>éœ€è¦æ›´è¯¦ç»†çš„äº‹æ•…å™è¿°æ¥æ„å»ºå› æœå…³ç³»",
                showarrow=False,
                font=dict(size=14, color='#7f8c8d'),
                xref="paper", yref="paper",
                align="center"
            )
            fig.update_layout(
                title="ğŸ”— äº‹æ•…å› æœå…³ç³»å›¾",
                xaxis=dict(visible=False),
                yaxis=dict(visible=False),
                height=400
            )
            return fig
        
        # ä½¿ç”¨NetworkXæ„å»ºå›¾
        G = nx.DiGraph()
        
        # æ·»åŠ èŠ‚ç‚¹
        for node in diagram.nodes:
            G.add_node(node.id, 
                      name=node.name, 
                      type=node.type, 
                      category=node.category,
                      impact=node.impact,
                      likelihood=node.likelihood)
        
        # æ·»åŠ è¾¹
        for rel in diagram.relationships:
            G.add_edge(rel.from_node, rel.to_node, 
                      type=rel.relationship_type, 
                      strength=rel.strength)
        
        # ä½¿ç”¨ä¸“ä¸šçš„å±‚æ¬¡åŒ–å¸ƒå±€ï¼Œç¬¦åˆäº‹æ•…è°ƒæŸ¥åˆ†æé€»è¾‘
        pos = self._create_hierarchical_layout(diagram, G)
        
        # åˆ›å»ºå¯è§†åŒ–
        fig = go.Figure()
        
        # ç»˜åˆ¶è¾¹
        for rel in diagram.relationships:
            if rel.from_node in pos and rel.to_node in pos:
                x0, y0 = pos[rel.from_node]
                x1, y1 = pos[rel.to_node]
                
                # è¾¹çš„é¢œè‰²åŸºäºç±»å‹
                line_color = {
                    'direct_cause': '#e74c3c',
                    'contributing_cause': '#f39c12', 
                    'enabling_condition': '#3498db'
                }.get(rel.relationship_type, '#95a5a6')
                
                # è¾¹çš„å®½åº¦åŸºäºå¼ºåº¦
                line_width = 1 + rel.strength * 3
                
                fig.add_trace(go.Scatter(
                    x=[x0, x1, None],
                    y=[y0, y1, None],
                    mode='lines',
                    line=dict(color=line_color, width=line_width),
                    showlegend=False,
                    hoverinfo='skip'
                ))
                
                # æ·»åŠ ç®­å¤´ï¼Œå¹¶åœ¨ä¸­ç‚¹æ·»åŠ å…³ç³»ç±»å‹æ ‡ç­¾
                mid_x, mid_y = (x0 + x1) / 2, (y0 + y1) / 2
                
                fig.add_annotation(
                    x=x1, y=y1,
                    ax=x0, ay=y0,
                    xref='x', yref='y',
                    axref='x', ayref='y',
                    showarrow=True,
                    arrowhead=2,
                    arrowsize=1.5,
                    arrowwidth=2,
                    arrowcolor=line_color
                )
                
                # æ·»åŠ å…³ç³»ç±»å‹æ ‡ç­¾
                rel_type_label = get_text(rel.relationship_type, lang) if rel.relationship_type in ['direct_cause', 'contributing_cause', 'enabling_condition'] else rel.relationship_type
                
                fig.add_annotation(
                    x=mid_x, y=mid_y,
                    text=f"<b>{rel_type_label}</b><br>({rel.strength:.1f})",
                    showarrow=False,
                    font=dict(size=12, color=line_color, family="Arial Black"),
                    bgcolor="white",
                    bordercolor=line_color,
                    borderwidth=1,
                    xref='x', yref='y'
                )
        
        # Draw nodes
        for node in diagram.nodes:
            if node.id in pos:
                x, y = pos[node.id]
                
                # èŠ‚ç‚¹é¢œè‰²åŸºäºç±»å‹
                node_color = self.node_colors.get(node.type, '#95a5a6')
                
                # èŠ‚ç‚¹å¤§å°åŸºäºå½±å“åº¦
                node_size = 20 + node.impact * 40
                
                # èŠ‚ç‚¹å½¢çŠ¶åŸºäºç±»åˆ«
                symbol = {
                    'human': 'circle',
                    'technical': 'square', 
                    'environmental': 'triangle-up',
                    'organizational': 'diamond',
                    'procedural': 'hexagon'
                }.get(node.category, 'circle')
                
                fig.add_trace(go.Scatter(
                    x=[x], y=[y],
                    mode='markers+text',
                    marker=dict(
                        size=node_size,
                        color=node_color,
                        symbol=symbol,
                        line=dict(width=2, color='white'),
                        opacity=0.8
                    ),
                    text=node.name,
                    textposition="bottom center",
                    textfont=dict(size=14, color='#2c3e50', family="Arial Black"),
                    name=node.type,
                    showlegend=False,
                    hovertemplate=(
                        f"<b>{node.name}</b><br>"
                        f"{get_text('type', lang)}: {get_text(node.type, lang)}<br>"
                        f"{get_text('category', lang)}: {get_text(node.category, lang)}<br>"
                        f"{get_text('likelihood', lang)}: {node.likelihood:.1%}<br>"
                        f"{get_text('impact', lang)}: {node.impact:.1%}<br>"
                        f"{get_text('evidence_strength', lang)}: {node.evidence_strength:.1%}<br>"
                        f"{node.description}"
                        "<extra></extra>"
                    )
                ))
        
        # æ·»åŠ å›¾ä¾‹
        legend_traces = []
        for node_type, color in self.node_colors.items():
            legend_traces.append(go.Scatter(
                x=[None], y=[None],
                mode='markers',
                marker=dict(size=12, color=color),
                name=node_type.replace('_', ' ').title(),
                showlegend=True
            ))
        
        for trace in legend_traces:
            fig.add_trace(trace)
        
        # æ·»åŠ å±‚çº§æ ‡ç­¾
        layer_labels = [
            (get_text("organizational_influences", lang), 4),
            (get_text("root_cause", lang), 3), 
            (get_text("contributing_factors", lang), 2),
            (get_text("direct_causes", lang), 1),
            (get_text("incident_consequences", lang), 0)
        ]
        
        for label, y_pos in layer_labels:
            fig.add_annotation(
                x=-5, y=y_pos,
                text=f"<b>{label}</b>",
                showarrow=False,
                font=dict(size=16, color='#2c3e50', family="Arial Black"),
                xref='x', yref='y',
                xanchor='right'
            )
        
        fig.update_layout(
            title={
                'text': f"ğŸ”— Professional Incident Causal Analysis Diagram<br><sub>{diagram.central_event}</sub>",
                'x': 0.5,
                'xanchor': 'center',
                'font': {'size': 16, 'color': '#2c3e50'}
            },
            xaxis=dict(
                showgrid=False, 
                zeroline=False, 
                showticklabels=False,
                range=[-6, 6]  # ä¸ºå±‚çº§æ ‡ç­¾ç•™å‡ºç©ºé—´
            ),
            yaxis=dict(
                showgrid=False, 
                zeroline=False, 
                showticklabels=False,
                range=[-0.5, 4.5]
            ),
            height=700,
            showlegend=True,
            legend=dict(
                orientation="v",
                yanchor="top",
                y=1,
                xanchor="left", 
                x=1.01,
                title="Node Type"
            ),
            plot_bgcolor='white',
            paper_bgcolor='#f8f9fa'
        )
        
        return fig
    
    def _create_hierarchical_layout(self, diagram: CausalDiagram, G) -> dict:
        """Create hierarchical layout that follows incident investigation logic"""
        
        # æŒ‰ç±»å‹åˆ†å±‚ï¼Œä»ä¸Šåˆ°ä¸‹ï¼šç»„ç»‡å› ç´  -> æ ¹æœ¬åŸå›  -> è´¡çŒ®å› ç´  -> ç›´æ¥åŸå›  -> åæœ
        layer_hierarchy = {
            'organizational': 0,     # æœ€é¡¶å±‚ï¼šç»„ç»‡å› ç´ 
            'root_cause': 1,        # æ ¹æœ¬åŸå› å±‚
            'contributing_factor': 2, # è´¡çŒ®å› ç´ å±‚  
            'immediate_cause': 3,    # ç›´æ¥åŸå› å±‚
            'consequence': 4         # åæœå±‚ï¼ˆæœ€åº•å±‚ï¼‰
        }
        
        # æŒ‰ç±»åˆ«åˆ†å±‚ï¼Œä»å·¦åˆ°å³ï¼šäººä¸º -> æŠ€æœ¯ -> ç¯å¢ƒ -> ç¨‹åº -> ç»„ç»‡
        category_order = {
            'human': 0,
            'technical': 1, 
            'environmental': 2,
            'procedural': 3,
            'organizational': 4
        }
        
        pos = {}
        layer_counts = {i: 0 for i in range(5)}  # æ¯å±‚çš„èŠ‚ç‚¹è®¡æ•°
        
        # é¦–æ¬¡éå†ï¼šè®¡ç®—æ¯å±‚èŠ‚ç‚¹æ•°
        for node in diagram.nodes:
            layer = layer_hierarchy.get(node.type, 2)  # é»˜è®¤ä¸ºè´¡çŒ®å› ç´ å±‚
            layer_counts[layer] += 1
        
        layer_positions = {i: 0 for i in range(5)}  # æ¯å±‚å½“å‰ä½ç½®è®¡æ•°
        
        # ç¬¬äºŒæ¬¡éå†ï¼šè®¡ç®—å®é™…ä½ç½®
        for node in diagram.nodes:
            layer = layer_hierarchy.get(node.type, 2)
            category_x_offset = category_order.get(node.category, 2) * 0.5
            
            # Yåæ ‡ï¼šæ ¹æ®å±‚æ¬¡ç¡®å®šï¼ˆé¡¶éƒ¨ä¸ºç»„ç»‡å› ç´ ï¼Œåº•éƒ¨ä¸ºåæœï¼‰
            y = 4 - layer  # åè½¬Yè½´ï¼Œä½¿ç»„ç»‡å› ç´ åœ¨é¡¶éƒ¨
            
            # Xåæ ‡ï¼šåœ¨è¯¥å±‚å†…å‡åŒ€åˆ†å¸ƒï¼Œå¹¶æ ¹æ®ç±»åˆ«ç¨ä½œåç§»
            layer_width = max(layer_counts[layer], 1)
            if layer_width == 1:
                x = category_x_offset
            else:
                x_base = (layer_positions[layer] / (layer_width - 1)) * 8 - 4  # åˆ†å¸ƒåœ¨-4åˆ°4ä¹‹é—´
                x = x_base + category_x_offset * 0.3  # åŠ ä¸Šç±»åˆ«åç§»
            
            pos[node.id] = (x, y)
            layer_positions[layer] += 1
        
        # å¦‚æœèŠ‚ç‚¹å¤ªå°‘ï¼Œä½¿ç”¨å¤‡ç”¨å¸ƒå±€
        if len(diagram.nodes) < 3:
            try:
                pos = nx.spring_layout(G, k=2, iterations=50)
            except:
                pos = nx.circular_layout(G)
        
        return pos

def main():
    """æµ‹è¯•å‡½æ•°"""
    generator = CausalDiagramGenerator()
    
    test_narrative = """
    åœ¨ä¸€æ¬¡è®­ç»ƒé£è¡Œä¸­ï¼Œæ— äººæœºåœ¨1500è‹±å°ºé«˜åº¦å·¡èˆªæ—¶çªç„¶å¤±å»äº†ä¸åœ°é¢æ§åˆ¶ç«™çš„é€šä¿¡è¿æ¥ã€‚
    é£è¡Œå‘˜å°è¯•é‡æ–°å»ºç«‹è”ç³»ä½†æœªæˆåŠŸï¼Œæ— äººæœºè‡ªåŠ¨å¯åŠ¨äº†è¿”èˆªæ¨¡å¼ã€‚
    å¤©æ°”æ¡ä»¶è‰¯å¥½ï¼Œèƒ½è§åº¦æ¸…æ™°ã€‚åæ¥å‘ç°æ˜¯é€šä¿¡è®¾å¤‡çš„å¤©çº¿è¿æ¥æ¾åŠ¨å¯¼è‡´äº†é€šä¿¡ä¸­æ–­ã€‚
    è¿™æš´éœ²äº†ç»´æŠ¤æ£€æŸ¥ç¨‹åºçš„ä¸è¶³ï¼Œä»¥åŠåº”æ€¥ç¨‹åºåŸ¹è®­çš„ç¼ºé™·ã€‚
    """
    
    diagram = generator.generate_causal_diagram(test_narrative)
    
    print("=== å› æœå›¾åˆ†æç»“æœ ===")
    print(f"ä¸­å¿ƒäº‹ä»¶: {diagram.central_event}")
    print(f"èŠ‚ç‚¹æ•°é‡: {len(diagram.nodes)}")
    print(f"å…³ç³»æ•°é‡: {len(diagram.relationships)}")
    print(f"é£é™©è·¯å¾„: {len(diagram.risk_paths)}")
    print(f"æ§åˆ¶ç‚¹: {len(diagram.control_points)}")
    
    # æ‰“å°èŠ‚ç‚¹ä¿¡æ¯
    print("\nèŠ‚ç‚¹è¯¦æƒ…:")
    for node in diagram.nodes:
        print(f"- {node.name} ({node.type}, {node.category}): {node.description}")

if __name__ == "__main__":
    main()